{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4e8429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 18:27:59.557955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/Users/chloelsmith/Desktop/archive-2/Grayscale_Training\"\n",
    "test_path = \"/Users/chloelsmith/Desktop/archive-2/Grayscale_Testing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 18:46:06.047118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/chloelsmith/anaconda3/envs/washu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5521 files belonging to 4 classes.\n",
      "Found 1205 files belonging to 4 classes.\n",
      "Generating embeddings for train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 18:52:51.300194: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "from cleanlab.rank import find_top_issues\n",
    "\n",
    "# -----------------------------\n",
    "# USER CONFIG\n",
    "# -----------------------------\n",
    "train_path = \"/Users/chloelsmith/Desktop/archive-2/Grayscale_Training\"\n",
    "test_path = \"/Users/chloelsmith/Desktop/archive-2/Grayscale_Testing\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 64  # Larger batch speeds up CPU runs\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD DATASETS (grayscale -> RGB)\n",
    "# -----------------------------\n",
    "def to_rgb(image, label):\n",
    "    image = tf.image.grayscale_to_rgb(image)             # Convert 1 channel â†’ 3\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize to [0,1]\n",
    "    return image, label\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ").map(to_rgb, num_parallel_calls=tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_path,\n",
    "    image_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ").map(to_rgb, num_parallel_calls=tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL: Pretrained ResNet50\n",
    "# -----------------------------\n",
    "base_model = ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    input_shape=(*img_size, 3)\n",
    ")\n",
    "model = models.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "model.trainable = False  # evaluation mode\n",
    "\n",
    "# -----------------------------\n",
    "# EMBEDDING FUNCTION\n",
    "# -----------------------------\n",
    "def embed_images(model, dataset, save_path=None):\n",
    "    feature_embeddings = []\n",
    "    for batch_images, _ in dataset:\n",
    "        embeddings = model(batch_images, training=False)\n",
    "        feature_embeddings.append(embeddings.numpy())\n",
    "    feature_embeddings = np.concatenate(feature_embeddings, axis=0)\n",
    "    \n",
    "    if save_path:\n",
    "        np.save(save_path, feature_embeddings)\n",
    "        print(f\"Saved embeddings to {save_path}\")\n",
    "        \n",
    "    return feature_embeddings\n",
    "\n",
    "# -----------------------------\n",
    "# GENERATE EMBEDDINGS\n",
    "# -----------------------------\n",
    "print(\"Generating embeddings for train set...\")\n",
    "train_feature_embeddings = embed_images(model, train_ds, save_path=\"train_embeddings.npy\")\n",
    "print(f\"Train embeddings shape: {train_feature_embeddings.shape}\")\n",
    "\n",
    "print(\"Generating embeddings for test set...\")\n",
    "test_feature_embeddings = embed_images(model, test_ds, save_path=\"test_embeddings.npy\")\n",
    "print(f\"Test embeddings shape: {test_feature_embeddings.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# CLEANLAB OOD DETECTION\n",
    "# -----------------------------\n",
    "ood = OutOfDistribution()\n",
    "train_ood_scores = ood.fit_score(features=train_feature_embeddings)\n",
    "\n",
    "# Find top outliers\n",
    "top_train_ood_idxs = find_top_issues(quality_scores=train_ood_scores, topk=15)\n",
    "print(\"Top possible OOD samples in training set:\")\n",
    "print(top_train_ood_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_outliers(top_train_ood_features_idxs, train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "washu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
